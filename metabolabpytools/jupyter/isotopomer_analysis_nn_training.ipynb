{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3cccf6-5bc3-43d6-bb55-0eef464dd9aa",
   "metadata": {},
   "source": [
    "## Neural Network Isopotopomer Analysis\n",
    "\n",
    "### Step 1 - Data simulation:\n",
    "\n",
    "- All data now simulated, find sim data in the relevant sim save. More/diverse datasets can be created to train the networks even further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107a8260-b16d-4d68-88aa-2a677300350c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T17:29:41.171816Z",
     "start_time": "2025-01-25T17:29:09.583170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to sim_data/sim_011.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from metabolabpytools import isotopomerAnalysis\n",
    "analysis = isotopomerAnalysis.IsotopomerAnalysisNN()\n",
    "\n",
    "# Define the HSQC vector externally\n",
    "hsqc_vector = [0, 1, 1] # For 3-carbon metabolites, all carbons participate in HSQC\n",
    "n_carbons = len(hsqc_vector)\n",
    "\n",
    "# Example usage\n",
    "synthetic_distributions = analysis.generate_isotopomer_distributions(n_distributions=1000, n_carbons=n_carbons)  \n",
    "\n",
    "\n",
    "# Simulate HSQC and GC-MS data for all distributions with the defined HSQC vector\n",
    "combined_isotopomer_data, combined_hsqc_data, combined_gcms_data = analysis.simulate_hsqc_gcms(synthetic_distributions, hsqc_vector)\n",
    "\n",
    "# Save the simulation data to a spreadsheet\n",
    "analysis.save_simulation_data(combined_isotopomer_data, combined_hsqc_data, combined_gcms_data, hsqc_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46217cb-a520-4d7c-8cce-9dff7e32c16b",
   "metadata": {},
   "source": [
    "### Step 2 - Data preparation:\n",
    "\n",
    "-Using [0, 1, 1, 0] as example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4282db9-9784-4e36-b788-73d8e86806ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.30513711  2.93557073  0.          0.          0.         29.40075459\n",
      " 31.35853757  0.        ]\n",
      "[1.21043515e+00 9.66659397e+01 9.78736970e-02 2.02575141e+00\n",
      " 9.79385109e+01 2.06148911e+00 3.63051371e+01 2.93557073e+00\n",
      " 6.07592922e+01 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from metabolabpytools import isotopomerAnalysis\n",
    "analysis = isotopomerAnalysis.IsotopomerAnalysisNN()\n",
    "\n",
    "# Example usage for HSQC vector [0,1,1]\n",
    "hsqc_vector = [0, 1, 1]\n",
    "num_carbons = len(hsqc_vector)\n",
    "isotopomer_data, hsqc_data, gcms_data = analysis.load_spreadsheet_by_hsqc_vector(hsqc_vector)\n",
    "\n",
    "all_possible_hsqc_multiplets = analysis.generate_possible_hsqc_multiplets(hsqc_vector)\n",
    "\n",
    "Y = analysis.collate_y_labels(isotopomer_data, num_carbons)\n",
    "\n",
    "X_noisy = analysis.collate_x_labels_without_noise(hsqc_data, gcms_data, all_possible_hsqc_multiplets)\n",
    "\n",
    "\n",
    "# # Now Y contains the isotopomer percentages for each sample, structured for training a neural network\n",
    "print(Y[7])\n",
    "print(X_noisy[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d392a5-6aad-48d4-b953-f46f6a77c73c",
   "metadata": {},
   "source": [
    "### Step 3 - Train a Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7818209f-e76b-4c3e-a4d6-ac5efa39f296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,008</span> (46.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,008\u001b[0m (46.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,008</span> (46.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,008\u001b[0m (46.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 436.2444 - mae: 11.4618 - val_loss: 114.0747 - val_mae: 7.5071\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 95.6169 - mae: 6.2994 - val_loss: 75.6897 - val_mae: 5.3527\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.7373 - mae: 5.1113 - val_loss: 51.7806 - val_mae: 4.1372\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 51.3473 - mae: 3.8870 - val_loss: 42.5595 - val_mae: 3.5736\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.4634 - mae: 3.4238 - val_loss: 35.6619 - val_mae: 3.2319\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.9306 - mae: 3.1919 - val_loss: 32.2328 - val_mae: 3.0134\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.3957 - mae: 3.1109 - val_loss: 30.1118 - val_mae: 2.8677\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.2980 - mae: 2.8340 - val_loss: 28.9598 - val_mae: 2.7401\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.7628 - mae: 2.8046 - val_loss: 27.3882 - val_mae: 2.5881\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6383 - mae: 2.5935 - val_loss: 26.7223 - val_mae: 2.5183\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.0800 - mae: 2.6030 - val_loss: 26.6237 - val_mae: 2.5192\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5999 - mae: 2.5248 - val_loss: 25.4712 - val_mae: 2.3684\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.8870 - mae: 2.3384 - val_loss: 25.6990 - val_mae: 2.4295\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25.5229 - mae: 2.4416 - val_loss: 25.1214 - val_mae: 2.3142\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.8672 - mae: 2.2684 - val_loss: 25.3958 - val_mae: 2.3116\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.7951 - mae: 2.3089 - val_loss: 24.6637 - val_mae: 2.3149\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.7417 - mae: 2.1929 - val_loss: 24.2365 - val_mae: 2.2263\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.4141 - mae: 2.1595 - val_loss: 24.6706 - val_mae: 2.2607\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.1537 - mae: 2.1293 - val_loss: 24.2313 - val_mae: 2.1988\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.5529 - mae: 2.1447 - val_loss: 23.9947 - val_mae: 2.2466\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.9506 - mae: 2.1570 - val_loss: 24.8753 - val_mae: 2.3058\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.9167 - mae: 2.1571 - val_loss: 23.5212 - val_mae: 2.1442\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.1895 - mae: 2.1209 - val_loss: 22.9970 - val_mae: 2.1613\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.2931 - mae: 2.1018 - val_loss: 23.6986 - val_mae: 2.1561\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.3380 - mae: 2.0460 - val_loss: 23.1478 - val_mae: 2.1478\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.7630 - mae: 1.9808 - val_loss: 22.7443 - val_mae: 2.1073\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.4996 - mae: 2.0297 - val_loss: 23.9056 - val_mae: 2.2600\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.3354 - mae: 2.0720 - val_loss: 23.2790 - val_mae: 2.1657\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.5690 - mae: 2.0194 - val_loss: 22.6237 - val_mae: 2.0336\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.8068 - mae: 1.8374 - val_loss: 22.4538 - val_mae: 2.0135\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.8341 - mae: 1.9167 - val_loss: 22.2099 - val_mae: 2.0062\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.1657 - mae: 1.9517 - val_loss: 22.4765 - val_mae: 2.0481\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.2025 - mae: 1.9437 - val_loss: 22.3796 - val_mae: 2.0139\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.8820 - mae: 1.9779 - val_loss: 22.3685 - val_mae: 2.0578\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.6908 - mae: 1.9413 - val_loss: 22.3924 - val_mae: 2.0631\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.9532 - mae: 1.9551 - val_loss: 23.1606 - val_mae: 2.1228\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.0889 - mae: 1.9673 - val_loss: 22.4854 - val_mae: 2.0748\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.2457 - mae: 1.8747 - val_loss: 22.7549 - val_mae: 2.0145\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.2802 - mae: 1.8951 - val_loss: 23.4698 - val_mae: 2.1211\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.7657 - mae: 1.9558 - val_loss: 21.9355 - val_mae: 1.9970\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.2381 - mae: 1.8335 - val_loss: 22.7465 - val_mae: 2.0578\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.6810 - mae: 1.8919 - val_loss: 21.9991 - val_mae: 1.9647\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.9614 - mae: 1.8452 - val_loss: 22.5277 - val_mae: 2.0179\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.3170 - mae: 1.8561 - val_loss: 22.0393 - val_mae: 2.0093\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.3558 - mae: 1.7531 - val_loss: 21.7004 - val_mae: 1.9386\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.9902 - mae: 1.7224 - val_loss: 21.6001 - val_mae: 1.9178\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.4665 - mae: 1.8138 - val_loss: 21.8939 - val_mae: 1.9505\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.5793 - mae: 1.7678 - val_loss: 21.7866 - val_mae: 1.9821\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.9197 - mae: 1.8484 - val_loss: 22.1612 - val_mae: 1.9640\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.9128 - mae: 1.8434 - val_loss: 21.7570 - val_mae: 1.9821\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4955 - mae: 1.8185 - val_loss: 21.3345 - val_mae: 1.9344\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.4151 - mae: 1.8082 - val_loss: 21.7337 - val_mae: 1.9832\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.1994 - mae: 1.7400 - val_loss: 22.0816 - val_mae: 2.0767\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0155 - mae: 1.8677 - val_loss: 21.6946 - val_mae: 1.9955\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.9275 - mae: 1.8008 - val_loss: 21.4312 - val_mae: 1.9066\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.2702 - mae: 1.7854 - val_loss: 22.1391 - val_mae: 2.0274\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.5582 - mae: 1.7414 - val_loss: 21.9700 - val_mae: 1.9590\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0793 - mae: 1.7832 - val_loss: 21.1425 - val_mae: 1.8712\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.2652 - mae: 1.7582 - val_loss: 21.0786 - val_mae: 1.9018\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.2016 - mae: 1.7048 - val_loss: 20.9365 - val_mae: 1.8650\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.8949 - mae: 1.6159 - val_loss: 21.7293 - val_mae: 1.9123\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.8466 - mae: 1.8093 - val_loss: 21.5810 - val_mae: 1.9355\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5001 - mae: 1.6720 - val_loss: 21.6179 - val_mae: 1.9183\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8471 - mae: 1.7595 - val_loss: 21.5940 - val_mae: 1.9692\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.6888 - mae: 1.7535 - val_loss: 21.2243 - val_mae: 1.8925\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.6371 - mae: 1.6706 - val_loss: 21.2830 - val_mae: 1.8877\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.5540 - mae: 1.7183 - val_loss: 21.1037 - val_mae: 1.8802\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7441 - mae: 1.6200 - val_loss: 20.9383 - val_mae: 1.8689\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7808 - mae: 1.6929 - val_loss: 21.3849 - val_mae: 1.8941\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5024 - mae: 1.7133 - val_loss: 20.9528 - val_mae: 1.8617\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.7239 - mae: 1.5825 - val_loss: 21.7017 - val_mae: 1.9277\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.2818 - mae: 1.5942 - val_loss: 21.3666 - val_mae: 1.9079\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.6263 - mae: 1.5744 - val_loss: 21.4444 - val_mae: 1.8902\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.5431 - mae: 1.6495 - val_loss: 21.2063 - val_mae: 1.8980\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.1053 - mae: 1.5872 - val_loss: 21.1725 - val_mae: 1.8961\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3853 - mae: 1.6738 - val_loss: 21.5283 - val_mae: 1.8502\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.9648 - mae: 1.6353 - val_loss: 22.1663 - val_mae: 1.9562\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.1778 - mae: 1.7444 - val_loss: 21.4203 - val_mae: 1.8639\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.1597 - mae: 1.5258 - val_loss: 21.3448 - val_mae: 1.9179\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7294 - mae: 1.6936 - val_loss: 20.9728 - val_mae: 1.8912\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5657 - mae: 1.6728 - val_loss: 20.8548 - val_mae: 1.8074\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1133 - mae: 1.6441 - val_loss: 21.0350 - val_mae: 1.8017\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.0445 - mae: 1.5773 - val_loss: 21.1280 - val_mae: 1.8480\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.4939 - mae: 1.5500 - val_loss: 21.0443 - val_mae: 1.8347\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.5076 - mae: 1.6457 - val_loss: 21.3467 - val_mae: 1.8265\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.8027 - mae: 1.5225 - val_loss: 21.0193 - val_mae: 1.8524\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2402 - mae: 1.5649 - val_loss: 21.8238 - val_mae: 1.9435\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8032 - mae: 1.7536 - val_loss: 21.1359 - val_mae: 1.8830\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.6158 - mae: 1.6140 - val_loss: 21.0972 - val_mae: 1.7999\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.6786 - mae: 1.5745 - val_loss: 20.6403 - val_mae: 1.7864\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.5956 - mae: 1.5297 - val_loss: 20.6882 - val_mae: 1.8358\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.8431 - mae: 1.5815 - val_loss: 21.4142 - val_mae: 1.9013\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.7527 - mae: 1.5995 - val_loss: 21.2056 - val_mae: 1.8702\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.8522 - mae: 1.5285 - val_loss: 21.6958 - val_mae: 1.9310\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.3538 - mae: 1.5607 - val_loss: 21.0923 - val_mae: 1.8320\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.0731 - mae: 1.5715 - val_loss: 21.1501 - val_mae: 1.8516\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.4602 - mae: 1.5873 - val_loss: 20.7772 - val_mae: 1.8196\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2728 - mae: 1.5966 - val_loss: 21.1591 - val_mae: 1.8287\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3918 - mae: 1.5510 - val_loss: 20.8558 - val_mae: 1.8354\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1161 - mae: 1.5756 - val_loss: 21.1112 - val_mae: 1.8227\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.4887 - mae: 1.8931 \n",
      "Validation Loss: 21.111160278320312, Validation MAE: 1.8227088451385498\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Predicted: [64.47649    5.7169857  0.         0.         9.01127    0.\n",
      "  3.5613022  0.       ], Actual: [63.71070564  0.          0.         13.00304901 14.23480463  4.76512861\n",
      "  4.2863121   0.        ]\n",
      "Predicted: [97.188995   0.         1.5493296  0.         0.         0.\n",
      "  0.         0.       ], Actual: [96.72523581  0.565807    0.69698828  0.68282275  0.          0.57968991\n",
      "  0.          0.74945625]\n",
      "Predicted: [92.81389    0.         0.         0.         0.9242283  0.\n",
      "  0.         5.1970005], Actual: [92.0763061   0.          0.          1.7677552   0.14266519  0.\n",
      "  1.35998927  4.65328424]\n",
      "Predicted: [98.114815  1.677931  0.        0.        0.        2.070332  0.\n",
      "  0.      ], Actual: [9.78901935e+01 6.67092617e-02 0.00000000e+00 1.00322875e+00\n",
      " 0.00000000e+00 1.03986853e+00 0.00000000e+00 0.00000000e+00]\n",
      "Predicted: [96.12559     1.3680478   0.          0.          0.          0.12234224\n",
      "  0.          0.78399384], Actual: [96.43185161  1.02055869  0.          1.14629787  0.          0.\n",
      "  0.          1.40129182]\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "model, history = analysis.train_neural_network(X_noisy, Y, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bd9d4-ffbe-418b-88c6-927950155846",
   "metadata": {},
   "source": [
    "### Step 4 - Hyperparamter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5732548-bcab-4dd6-9dce-6c06be4bef7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuning_dir\\metabolite_tuning_0_1_1\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 10\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 6, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': 64, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "l2_lambda (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "units_1 (Int)\n",
      "{'default': 64, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': 64, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': 64, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': 64, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "units_5 (Int)\n",
      "{'default': 64, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "Results summary\n",
      "Results in tuning_dir\\metabolite_tuning_0_1_1\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 123 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "l2_lambda: 1e-05\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.0006502850999769697\n",
      "units_1: 32\n",
      "units_2: 256\n",
      "units_3: 512\n",
      "units_4: 512\n",
      "units_5: 512\n",
      "Score: 1.332837700843811\n",
      "\n",
      "Trial 111 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "l2_lambda: 0.0009227356786965785\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.00024305419486372304\n",
      "units_1: 32\n",
      "units_2: 96\n",
      "units_3: 160\n",
      "units_4: 256\n",
      "units_5: 512\n",
      "Score: 1.3575760126113892\n",
      "\n",
      "Trial 064 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 448\n",
      "l2_lambda: 5.923810299754347e-05\n",
      "dropout_rate: 0.15000000000000002\n",
      "learning_rate: 0.00013647819842956492\n",
      "units_1: 288\n",
      "units_2: 320\n",
      "units_3: 416\n",
      "units_4: 32\n",
      "units_5: 32\n",
      "Score: 1.3686290979385376\n",
      "\n",
      "Trial 077 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 480\n",
      "l2_lambda: 0.00019865592523972213\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.0005587587326337125\n",
      "units_1: 32\n",
      "units_2: 128\n",
      "units_3: 512\n",
      "units_4: 96\n",
      "units_5: 512\n",
      "Score: 1.4232876300811768\n",
      "\n",
      "Trial 069 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 448\n",
      "l2_lambda: 0.0003427706205885411\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.0005537295901814462\n",
      "units_1: 288\n",
      "units_2: 512\n",
      "units_3: 512\n",
      "units_4: 32\n",
      "units_5: 160\n",
      "Score: 1.4338780641555786\n",
      "\n",
      "Trial 162 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 320\n",
      "l2_lambda: 6.057299734164204e-05\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.0007890957880705852\n",
      "units_1: 32\n",
      "units_2: 32\n",
      "units_3: 352\n",
      "units_4: 352\n",
      "units_5: 512\n",
      "Score: 1.5069626569747925\n",
      "\n",
      "Trial 151 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "l2_lambda: 0.00018150503127415773\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 0.0002006835004182101\n",
      "units_1: 288\n",
      "units_2: 224\n",
      "units_3: 384\n",
      "units_4: 512\n",
      "units_5: 512\n",
      "Score: 1.6037156581878662\n",
      "\n",
      "Trial 124 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "l2_lambda: 8.282609031465146e-05\n",
      "dropout_rate: 0.25\n",
      "learning_rate: 0.0006175569637719829\n",
      "units_1: 128\n",
      "units_2: 512\n",
      "units_3: 512\n",
      "units_4: 512\n",
      "units_5: 192\n",
      "Score: 1.68063485622406\n",
      "\n",
      "Trial 157 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "l2_lambda: 7.38063214968301e-05\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.0006418356499227484\n",
      "units_1: 224\n",
      "units_2: 512\n",
      "units_3: 512\n",
      "units_4: 288\n",
      "units_5: 416\n",
      "Score: 1.7888296842575073\n",
      "\n",
      "Trial 163 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 512\n",
      "l2_lambda: 9.09808593748106e-05\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 0.0006950353628271031\n",
      "units_1: 32\n",
      "units_2: 352\n",
      "units_3: 256\n",
      "units_4: 512\n",
      "units_5: 512\n",
      "Score: 1.7917280197143555\n",
      "WARNING:tensorflow:From C:\\Users\\raath\\metabolabpytools\\venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raath\\metabolabpytools\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2612 - mae: 0.5057  \n",
      "Validation Loss: 1.184056282043457, Validation MAE: 0.5080022215843201\n",
      "Model saved as model_hsqc_0_1_1.keras in saved_models\n",
      "Model summary saved as model_summaries\\model_summary_model_hsqc_0_1_1.keras.csv\n",
      "Sample 1 - Predicted Mean: [6.4169510e+01 3.8595462e+00 3.0425385e-02 1.5208347e+01 1.0706774e+01\n",
      " 1.6648872e+00 4.3416262e+00 1.8878680e-02], Standard Deviation: [0.7759514  0.86551386 0.11955384 0.55404705 0.8135083  0.68452483\n",
      " 0.43322873 0.09800316]\n",
      "Sample 2 - Predicted Mean: [9.7873039e+01 1.7049019e-01 1.7444493e-01 7.3877174e-01 1.4755067e-02\n",
      " 2.6346290e-01 0.0000000e+00 7.6505297e-01], Standard Deviation: [0.91222733 0.39468086 0.28344423 0.33390424 0.13124508 0.34827974\n",
      " 0.         0.31846523]\n",
      "Sample 3 - Predicted Mean: [9.2271423e+01 5.1886733e-03 0.0000000e+00 1.7194188e+00 1.9766326e-01\n",
      " 4.3332912e-03 1.3607365e+00 4.4412503e+00], Standard Deviation: [0.7248941  0.03637074 0.         0.34630585 0.48410395 0.03036956\n",
      " 0.35417482 0.35238534]\n",
      "Sample 4 - Predicted Mean: [9.8000656e+01 7.5008400e-02 1.6768148e-02 1.5402112e+00 0.0000000e+00\n",
      " 3.6220512e-01 0.0000000e+00 5.1408219e-03], Standard Deviation: [0.6889023  0.22475353 0.11243334 0.40168184 0.         0.43463868\n",
      " 0.         0.03487431]\n",
      "Sample 5 - Predicted Mean: [9.6409813e+01 6.0551500e-01 7.1590231e-04 1.4483192e+00 0.0000000e+00\n",
      " 4.0087745e-02 0.0000000e+00 1.4955391e+00], Standard Deviation: [0.7391679  0.58366954 0.00712314 0.309012   0.         0.12470626\n",
      " 0.         0.3280547 ]\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Predicted: [64.12637    3.7345939  0.        15.184678  10.948536   1.769194\n",
      "  4.2366276  0.       ], Actual: [63.71070564  0.          0.         13.00304901 14.23480463  4.76512861\n",
      "  4.2863121   0.        ]\n",
      "Predicted: [9.8295891e+01 0.0000000e+00 2.5229001e-02 7.4183714e-01 0.0000000e+00\n",
      " 1.4762029e-01 0.0000000e+00 7.8942263e-01], Actual: [96.72523581  0.565807    0.69698828  0.68282275  0.          0.57968991\n",
      "  0.          0.74945625]\n",
      "Predicted: [92.43074    0.         0.         1.7589854  0.         0.\n",
      "  1.3526502  4.457628 ], Actual: [92.0763061   0.          0.          1.7677552   0.14266519  0.\n",
      "  1.35998927  4.65328424]\n",
      "Predicted: [9.8445297e+01 0.0000000e+00 0.0000000e+00 1.4820246e+00 0.0000000e+00\n",
      " 7.2678328e-02 0.0000000e+00 0.0000000e+00], Actual: [9.78901935e+01 6.67092617e-02 0.00000000e+00 1.00322875e+00\n",
      " 0.00000000e+00 1.03986853e+00 0.00000000e+00 0.00000000e+00]\n",
      "Predicted: [96.63006     0.49620113  0.          1.4234416   0.          0.\n",
      "  0.          1.4502949 ], Actual: [96.43185161  1.02055869  0.          1.14629787  0.          0.\n",
      "  0.          1.40129182]\n"
     ]
    }
   ],
   "source": [
    "hsqc_vector = [0, 1, 1]  # Replace with your actual HSQC vector\n",
    "\n",
    "# Tune the model, save it, and generate a summary\n",
    "best_model, X_val, Y_val, mean_pred, std_dev_pred = analysis.tune_model(X_noisy, Y, hsqc_vector)\n",
    "\n",
    "# Make predictions\n",
    "predictions = best_model.predict(X_val)\n",
    "\n",
    "# Example: Comparing normalized predictions with actual Y values\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {predictions[i]}, Actual: {Y_val[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfa0d5-0cf7-4138-8aea-413f441a9bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
