{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3cccf6-5bc3-43d6-bb55-0eef464dd9aa",
   "metadata": {},
   "source": [
    "## Neural Network Isopotopomer Analysis\n",
    "\n",
    "### Step 1 - Data simulation:\n",
    "\n",
    "- Simply change the HSQC vector to simulate the dataset for each Metabolite..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "107a8260-b16d-4d68-88aa-2a677300350c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T09:37:05.280962Z",
     "start_time": "2025-03-21T09:36:47.534290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to sim_data/sim_011.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from metabolabpytools import isotopomerAnalysis\n",
    "analysis = isotopomerAnalysis.IsotopomerAnalysisNN()\n",
    "\n",
    "# Define the HSQC vector externally\n",
    "hsqc_vector = [0, 1, 1] # For 3-carbon metabolites, all carbons participate in HSQC\n",
    "n_carbons = len(hsqc_vector)\n",
    "\n",
    "# Example usage\n",
    "synthetic_distributions = analysis.generate_isotopomer_distributions(n_distributions=10000, n_carbons=n_carbons)  \n",
    "\n",
    "\n",
    "# Simulate HSQC and GC-MS data for all distributions with the defined HSQC vector\n",
    "combined_isotopomer_data, combined_hsqc_data, combined_gcms_data = analysis.simulate_hsqc_gcms(synthetic_distributions, hsqc_vector)\n",
    "\n",
    "# Save the simulation data to a spreadsheet\n",
    "analysis.save_simulation_data(combined_isotopomer_data, combined_hsqc_data, combined_gcms_data, hsqc_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46217cb-a520-4d7c-8cce-9dff7e32c16b",
   "metadata": {},
   "source": [
    "### Step 2 - Data preparation:\n",
    "\n",
    "-Using [0, 1, 1] as example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4282db9-9784-4e36-b788-73d8e86806ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66.75361619  8.81435076  0.          0.         13.32781216  0.\n",
      "  8.95823859  2.1459823 ]\n",
      "[ 5.9248416   0.          0.          0.         80.39001317  0.\n",
      " 66.75361619 22.14216292  8.95823859  2.1459823 ]\n"
     ]
    }
   ],
   "source": [
    "from metabolabpytools import isotopomerAnalysis\n",
    "analysis = isotopomerAnalysis.IsotopomerAnalysisNN()\n",
    "\n",
    "# Example usage for HSQC vector [0,1,1]\n",
    "hsqc_vector = [0, 1, 1]\n",
    "num_carbons = len(hsqc_vector)\n",
    "isotopomer_data, hsqc_data, gcms_data = analysis.load_spreadsheet_by_hsqc_vector(hsqc_vector)\n",
    "\n",
    "all_possible_hsqc_multiplets = analysis.generate_possible_hsqc_multiplets(hsqc_vector)\n",
    "\n",
    "Y = analysis.collate_y_labels(isotopomer_data, num_carbons)\n",
    "\n",
    "X_noisy = analysis.collate_x_labels_without_noise(hsqc_data, gcms_data, all_possible_hsqc_multiplets)\n",
    "\n",
    "\n",
    "# # Now Y contains the isotopomer percentages for each sample, structured for training a neural network\n",
    "print(Y[7])\n",
    "print(X_noisy[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d392a5-6aad-48d4-b953-f46f6a77c73c",
   "metadata": {},
   "source": [
    "### Step 3 - Train a Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7818209f-e76b-4c3e-a4d6-ac5efa39f296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,008</span> (46.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,008\u001b[0m (46.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,008</span> (46.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,008\u001b[0m (46.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 82.8759 - mae: 5.0800 - val_loss: 43.1794 - val_mae: 3.3263\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 43.2522 - mae: 3.2169 - val_loss: 40.9224 - val_mae: 3.1834\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 41.2654 - mae: 3.0925 - val_loss: 40.6295 - val_mae: 3.1516\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 41.3648 - mae: 3.0766 - val_loss: 40.2354 - val_mae: 3.0545\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 41.0125 - mae: 3.0616 - val_loss: 40.0134 - val_mae: 3.0348\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40.1907 - mae: 3.0077 - val_loss: 40.0336 - val_mae: 3.0999\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40.2337 - mae: 2.9962 - val_loss: 39.3696 - val_mae: 2.9707\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39.6025 - mae: 2.9737 - val_loss: 39.1007 - val_mae: 2.9633\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 40.2564 - mae: 2.9554 - val_loss: 39.1543 - val_mae: 2.9678\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39.4814 - mae: 2.9407 - val_loss: 39.7083 - val_mae: 3.0211\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38.7313 - mae: 2.9275 - val_loss: 38.9060 - val_mae: 2.9833\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38.9368 - mae: 2.9149 - val_loss: 38.8339 - val_mae: 2.9728\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38.4745 - mae: 2.9115 - val_loss: 38.7633 - val_mae: 2.9425\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 38.6118 - mae: 2.8993 - val_loss: 38.4157 - val_mae: 2.9442\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.9496 - mae: 2.9006 - val_loss: 38.1048 - val_mae: 2.8953\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 31.9643 - mae: 2.6897 - val_loss: 26.9517 - val_mae: 2.3209\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 27.0798 - mae: 2.3484 - val_loss: 26.6804 - val_mae: 2.3189\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 26.7846 - mae: 2.3307 - val_loss: 26.7140 - val_mae: 2.3407\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 26.4011 - mae: 2.2718 - val_loss: 26.2735 - val_mae: 2.2369\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.9870 - mae: 2.2221 - val_loss: 26.0910 - val_mae: 2.2482\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.7579 - mae: 2.2246 - val_loss: 25.8725 - val_mae: 2.2456\n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.5040 - mae: 2.2220 - val_loss: 25.7927 - val_mae: 2.2209\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.8427 - mae: 2.1810 - val_loss: 25.9217 - val_mae: 2.2303\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.9695 - mae: 2.1901 - val_loss: 25.2848 - val_mae: 2.1732\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.1987 - mae: 2.1505 - val_loss: 25.2558 - val_mae: 2.1627\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.2990 - mae: 2.1375 - val_loss: 25.0894 - val_mae: 2.1603\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 24.8741 - mae: 2.1837 - val_loss: 25.3920 - val_mae: 2.1605\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.4245 - mae: 2.0720 - val_loss: 24.4042 - val_mae: 2.1255\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.7860 - mae: 2.1306 - val_loss: 24.9991 - val_mae: 2.2258\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.8787 - mae: 2.0752 - val_loss: 24.2463 - val_mae: 2.1586\n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.6633 - mae: 2.0887 - val_loss: 23.9089 - val_mae: 2.0805\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.4764 - mae: 2.0917 - val_loss: 24.2470 - val_mae: 2.1128\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.3752 - mae: 2.0823 - val_loss: 24.8118 - val_mae: 2.1750\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.5323 - mae: 2.0400 - val_loss: 23.8900 - val_mae: 2.0890\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.5598 - mae: 2.0907 - val_loss: 24.1044 - val_mae: 2.1095\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.0891 - mae: 2.0387 - val_loss: 23.6249 - val_mae: 2.0582\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.4440 - mae: 2.0431 - val_loss: 23.8372 - val_mae: 2.0606\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.1560 - mae: 2.0066 - val_loss: 24.3460 - val_mae: 2.1316\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.5054 - mae: 2.0228 - val_loss: 23.3241 - val_mae: 2.0298\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.6029 - mae: 1.9971 - val_loss: 23.2932 - val_mae: 2.0380\n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.7471 - mae: 1.9845 - val_loss: 23.4370 - val_mae: 2.0350\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.8202 - mae: 1.9867 - val_loss: 23.4150 - val_mae: 2.0786\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.6377 - mae: 2.0204 - val_loss: 23.4989 - val_mae: 2.0462\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.0785 - mae: 1.9951 - val_loss: 23.5037 - val_mae: 2.0289\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.3392 - mae: 2.0260 - val_loss: 23.2599 - val_mae: 2.0174\n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.6997 - mae: 2.0051 - val_loss: 23.6823 - val_mae: 2.0501\n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.2292 - mae: 2.0300 - val_loss: 24.0759 - val_mae: 2.1329\n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.3702 - mae: 2.0199 - val_loss: 23.6374 - val_mae: 2.0661\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.3279 - mae: 1.9674 - val_loss: 22.6237 - val_mae: 1.9648\n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.8035 - mae: 1.9337 - val_loss: 23.1797 - val_mae: 1.9985\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.3616 - mae: 1.9612 - val_loss: 23.0049 - val_mae: 1.9884\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.2180 - mae: 1.9416 - val_loss: 22.7617 - val_mae: 2.0233\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.4642 - mae: 1.9817 - val_loss: 23.2091 - val_mae: 2.0170\n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.7734 - mae: 1.9124 - val_loss: 22.5857 - val_mae: 1.9898\n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.9741 - mae: 1.9526 - val_loss: 22.8656 - val_mae: 2.0465\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.3319 - mae: 1.9452 - val_loss: 23.0128 - val_mae: 2.0262\n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.7687 - mae: 1.9199 - val_loss: 22.7787 - val_mae: 2.0401\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 23.1563 - mae: 2.0102 - val_loss: 22.6326 - val_mae: 2.0044\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.1112 - mae: 1.9693 - val_loss: 22.4690 - val_mae: 1.9702\n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.3001 - mae: 1.9352 - val_loss: 22.2170 - val_mae: 1.9552\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.4550 - mae: 1.9302 - val_loss: 22.9578 - val_mae: 2.0110\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.1633 - mae: 1.9488 - val_loss: 22.8721 - val_mae: 1.9996\n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.1187 - mae: 1.9332 - val_loss: 22.3070 - val_mae: 1.9629\n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.1568 - mae: 1.9084 - val_loss: 22.9072 - val_mae: 1.9887\n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.2981 - mae: 1.9311 - val_loss: 22.3008 - val_mae: 1.9533\n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.8739 - mae: 1.9342 - val_loss: 23.1215 - val_mae: 2.0380\n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.8415 - mae: 1.9425 - val_loss: 22.1732 - val_mae: 1.9306\n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.3574 - mae: 1.8918 - val_loss: 22.5086 - val_mae: 1.9992\n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.5170 - mae: 1.9146 - val_loss: 22.4571 - val_mae: 1.9435\n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.7567 - mae: 1.8864 - val_loss: 22.7565 - val_mae: 2.0405\n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.1738 - mae: 1.9622 - val_loss: 22.5652 - val_mae: 1.9710\n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.6434 - mae: 1.8900 - val_loss: 22.8233 - val_mae: 2.0281\n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.5869 - mae: 1.9037 - val_loss: 22.4821 - val_mae: 1.9643\n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.2874 - mae: 1.8664 - val_loss: 22.2146 - val_mae: 1.9662\n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.1903 - mae: 1.8889 - val_loss: 22.4136 - val_mae: 1.9692\n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.8313 - mae: 1.8797 - val_loss: 22.4792 - val_mae: 1.9647\n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.4662 - mae: 1.8607 - val_loss: 22.0493 - val_mae: 1.9248\n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.4104 - mae: 1.9044 - val_loss: 22.1951 - val_mae: 1.9137\n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.4442 - mae: 1.8998 - val_loss: 22.6068 - val_mae: 1.9547\n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.9654 - mae: 1.8703 - val_loss: 22.6012 - val_mae: 1.9537\n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.9387 - mae: 1.8666 - val_loss: 22.0244 - val_mae: 1.9308\n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.0454 - mae: 1.8737 - val_loss: 22.2302 - val_mae: 1.9232\n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.6306 - mae: 1.8480 - val_loss: 21.9201 - val_mae: 1.9061\n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.2051 - mae: 1.8393 - val_loss: 21.9203 - val_mae: 1.9474\n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.7319 - mae: 1.8567 - val_loss: 22.1781 - val_mae: 1.9395\n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.0225 - mae: 1.8456 - val_loss: 21.8567 - val_mae: 1.9412\n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.8397 - mae: 1.8434 - val_loss: 21.9890 - val_mae: 1.9098\n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.8531 - mae: 1.8804 - val_loss: 22.0259 - val_mae: 1.8904\n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.1029 - mae: 1.8708 - val_loss: 22.4238 - val_mae: 1.9267\n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.0933 - mae: 1.8277 - val_loss: 22.1792 - val_mae: 1.9171\n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.5370 - mae: 1.7983 - val_loss: 22.3162 - val_mae: 1.9151\n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.4046 - mae: 1.8627 - val_loss: 22.1585 - val_mae: 1.9173\n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.6097 - mae: 1.8865 - val_loss: 22.3412 - val_mae: 1.9318\n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.7649 - mae: 1.8457 - val_loss: 22.1771 - val_mae: 1.8919\n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.9624 - mae: 1.8840 - val_loss: 22.6313 - val_mae: 1.9697\n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.2362 - mae: 1.8364 - val_loss: 22.3894 - val_mae: 1.9269\n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.4596 - mae: 1.8201 - val_loss: 21.9942 - val_mae: 1.8898\n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.8801 - mae: 1.8094 - val_loss: 22.2866 - val_mae: 1.9546\n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.4803 - mae: 1.8789 - val_loss: 22.2557 - val_mae: 1.9069\n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.9665 - mae: 1.8378 - val_loss: 22.2519 - val_mae: 1.9256\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.6224 - mae: 1.9353\n",
      "Validation Loss: 22.25190544128418, Validation MAE: 1.925645112991333\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Predicted: [35.926987  0.        0.        0.       21.897861  0.       14.435903\n",
      "  0.      ], Actual: [35.25590641 21.50321184  0.          0.         31.88566186  0.\n",
      " 11.3552199   0.        ]\n",
      "Predicted: [53.731945  0.       19.068277  0.        8.832503 13.373958  0.\n",
      "  0.      ], Actual: [53.38097277  0.         15.35483179  0.         18.14949997 13.11469548\n",
      "  0.          0.        ]\n",
      "Predicted: [47.1627    0.       26.74532   0.        9.716495 13.997928  0.\n",
      "  0.      ], Actual: [46.56674934  0.         39.88061632  0.          0.         13.55263435\n",
      "  0.          0.        ]\n",
      "Predicted: [80.72446    0.         0.         0.         0.        12.447999\n",
      "  2.8204067  3.4347959], Actual: [81.02264084  0.          0.          0.          0.         13.01944726\n",
      "  2.75764966  3.20026224]\n",
      "Predicted: [90.80482     0.          1.9384841   0.          2.2952907   0.38703808\n",
      "  2.8010828   0.        ], Actual: [90.73908783  5.11930519  0.          0.          1.11657721  2.25313151\n",
      "  0.77189826  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "model, history = analysis.train_neural_network(X_noisy, Y, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bd9d4-ffbe-418b-88c6-927950155846",
   "metadata": {},
   "source": [
    "### Step 4 - Hyperparamter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5732548-bcab-4dd6-9dce-6c06be4bef7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 02m 09s]\n",
      "val_loss: 24.612380981445312\n",
      "\n",
      "Best val_loss So Far: 24.612380981445312\n",
      "Total elapsed time: 00h 02m 09s\n",
      "Results summary\n",
      "Results in tuning_dir\\metabolite_tuning_0_1_1\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 256\n",
      "l2_lambda: 0.0005196196720783069\n",
      "dropout_rate: 0.35\n",
      "learning_rate: 0.0004731616841237643\n",
      "units_1: 64\n",
      "units_2: 64\n",
      "units_3: 64\n",
      "units_4: 64\n",
      "units_5: 64\n",
      "Score: 24.612380981445312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raath\\PycharmProjects\\MachineLearningProject\\HDRC_Project\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.9118 - mae: 3.0731 \n",
      "Validation Loss: 24.953990936279297, Validation MAE: 3.0751802921295166\n",
      "Model saved as model_hsqc_0_1_1.keras in saved_models\n",
      "Model summary saved as model_summaries\\model_summary_model_hsqc_0_1_1.keras.csv\n",
      "Sample 1 - Predicted Mean: [38.756763   28.186247    0.77291363  1.3284677  23.250557    2.140741\n",
      "  4.6960964   0.8683415 ], Standard Deviation: [3.2958903 4.0296903 2.271225  2.2773743 4.7236233 3.0484605 3.6987307\n",
      " 2.3460479]\n",
      "Sample 2 - Predicted Mean: [54.86672    5.886317  17.609383   1.9431293  5.4999166 10.570859\n",
      "  2.8621068  0.7615194], Standard Deviation: [3.7529109 1.7066189 3.5601623 1.6974937 1.1273539 4.3162346 1.9361151\n",
      " 1.2097173]\n",
      "Sample 3 - Predicted Mean: [45.95286    7.1281343 23.394268   2.2295096  6.8449    10.910547\n",
      "  2.4487073  1.0909852], Standard Deviation: [4.242777  2.0748525 4.211551  2.11601   1.2468145 4.8846188 1.9756453\n",
      " 1.5751593]\n",
      "Sample 4 - Predicted Mean: [78.575836   2.9460456  1.7272013  2.603001   2.5207186  5.809499\n",
      "  4.7750816  1.0430528], Standard Deviation: [3.9175375  0.9586501  1.2022743  1.6365802  0.70367175 3.1996427\n",
      " 2.138408   1.6145225 ]\n",
      "Sample 5 - Predicted Mean: [91.813385    1.5495166   1.606029    1.1132716   0.907914    1.4141103\n",
      "  1.4571345   0.13883333], Standard Deviation: [3.3849554  0.4978941  0.8416785  0.9995215  0.86603636 0.67393684\n",
      " 0.5607178  0.6275992 ]\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Predicted: [39.11981    31.604116    0.          0.         25.276098    0.38796183\n",
      "  3.6120155   0.        ], Actual: [35.25590641 21.50321184  0.          0.         31.88566186  0.\n",
      " 11.3552199   0.        ]\n",
      "Predicted: [55.095898   5.6994843 17.872717   1.3302877  5.356695  12.152988\n",
      "  2.491925   0.       ], Actual: [53.38097277  0.         15.35483179  0.         18.14949997 13.11469548\n",
      "  0.          0.        ]\n",
      "Predicted: [46.031822   7.344593  23.329082   1.2942026  6.892745  13.147521\n",
      "  1.9600401  0.       ], Actual: [46.56674934  0.         39.88061632  0.          0.         13.55263435\n",
      "  0.          0.        ]\n",
      "Predicted: [78.83206    3.2632515  1.2075849  2.0237756  2.47931    6.773068\n",
      "  5.420949   0.       ], Actual: [81.02264084  0.          0.          0.          0.         13.01944726\n",
      "  2.75764966  3.20026224]\n",
      "Predicted: [9.4324654e+01 1.3577572e+00 1.4762441e+00 4.0805894e-01 5.7563297e-02\n",
      " 1.1392603e+00 1.2364577e+00 0.0000000e+00], Actual: [90.73908783  5.11930519  0.          0.          1.11657721  2.25313151\n",
      "  0.77189826  0.        ]\n"
     ]
    }
   ],
   "source": [
    "hsqc_vector = [0, 1, 1]  # Replace with your actual HSQC vector\n",
    "from metabolabpytools import isotopomerAnalysis\n",
    "analysis = isotopomerAnalysis.IsotopomerAnalysisNN()\n",
    "\n",
    "\n",
    "# Tune the model, save it, and generate a summary\n",
    "best_model, X_val, Y_val, mean_pred, std_dev_pred = analysis.tune_model(X_noisy, Y, hsqc_vector)\n",
    "\n",
    "# Make predictions\n",
    "predictions = best_model.predict(X_val)\n",
    "\n",
    "# Example: Comparing normalized predictions with actual Y values\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {predictions[i]}, Actual: {Y_val[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfa0d5-0cf7-4138-8aea-413f441a9bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
